{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Limulator Docs Limulator // Some image Limulator, i.e. LiDAR + Simulator, is a tool intended to simulate the lidar data generation and labelling process. Since then, it has come a long way to become a platform to actively support the development and testing of autonomous driving systems. As the development of autonomous systems picks pace, it has become absolutely critical to extensively test them in virtual environments before deploying them in public settings. Here we present one solution for that purpose: Limulator, a flexible simulator for point clouds, autonomous driving and much more. Simulator The simulator is built upon Blender, which provides support for the computation of high-fidelity physics, and simulation rendering and controls all the actors. Limulator controls the trajectories of actors, sensors, cameras and platforms by providing a UI interface inside Blender. // Some grahic image explaining connection of blender and limulator To gain a perspective on the structure of the Limulator, some of the major components are listed below: Scene : A scene is a 3D real-world model, generated in a blend file. Platforms : Platforms are all objects, dynamic and static, where sensors and cameras can be embedded. They can be chosen from the scene or imported from outside. Sensors : Sensors are static objects fixed on platforms. Currently, limulator only supports LiDar sensors. Cameras : Common as sensors, cameras are static objects fixed on platforms. Camera support in the limulator is implemented through the Blender camera module. Check out some quick demos. // Demo 1 (Car lidar) // Demo 2 (Car camera) // Demo 3 (Drone lidar) // Demo 4 (Drone camera maybe?)","title":"Welcome to Limulator Docs"},{"location":"#welcome-to-limulator-docs","text":"","title":"Welcome to Limulator Docs"},{"location":"#limulator","text":"// Some image Limulator, i.e. LiDAR + Simulator, is a tool intended to simulate the lidar data generation and labelling process. Since then, it has come a long way to become a platform to actively support the development and testing of autonomous driving systems. As the development of autonomous systems picks pace, it has become absolutely critical to extensively test them in virtual environments before deploying them in public settings. Here we present one solution for that purpose: Limulator, a flexible simulator for point clouds, autonomous driving and much more.","title":"Limulator"},{"location":"#simulator","text":"The simulator is built upon Blender, which provides support for the computation of high-fidelity physics, and simulation rendering and controls all the actors. Limulator controls the trajectories of actors, sensors, cameras and platforms by providing a UI interface inside Blender. // Some grahic image explaining connection of blender and limulator To gain a perspective on the structure of the Limulator, some of the major components are listed below: Scene : A scene is a 3D real-world model, generated in a blend file. Platforms : Platforms are all objects, dynamic and static, where sensors and cameras can be embedded. They can be chosen from the scene or imported from outside. Sensors : Sensors are static objects fixed on platforms. Currently, limulator only supports LiDar sensors. Cameras : Common as sensors, cameras are static objects fixed on platforms. Camera support in the limulator is implemented through the Blender camera module. Check out some quick demos. // Demo 1 (Car lidar) // Demo 2 (Car camera) // Demo 3 (Drone lidar) // Demo 4 (Drone camera maybe?)","title":"Simulator"},{"location":"SUMMARY/","text":"Overview Getting Started Tutorials System Documentation References API Reference Laser Module Camera Module Platform Module UI Server Processing Others","title":"SUMMARY"},{"location":"overview/","text":"Overview Scene Generation with Blender Not yet ready. Platforms [slide-20-image.jpg] Now that the scene is generated, it is time to add some sensors, but before that, we must specify platform objects. Platform objects are the parent objects where sensors are embedded, e.g. vehicles, drones, etc. It could be a fixed object with no trajectory(i.e. static), a dynamic object with a trajectory imported from outside or an actor(dynamic object inside the scene). Regardless, a platform with a known trajectory must be created before creating any sensors. Sensors [slide-22-image.jpg] With platform/platforms ready, sensors could now be created. The process is very similar to creating platforms; a location and orientation with respect to the platform must be provided. For e.g., if the sensor is placed at the platform's centre, the location must be (0, 0, 0). Remaining parameters like PRF, Scanning frequency, Channels, etc., are generic to the lidars sensors and can be copied as it is from the specification manual of the sensor. Cameras [slide-23-image.jpg] Adding a camera sensor is just the same as adding a lidar sensor with camera-specific parameters like focal length, iso, etc. Limulate! [slide-25-image.jpg] This is where the magic happens. But before that note, a standard dynamic model in Blender runs at 30fps, but the laser works on 2k-800k Hz. Rendering a simulation at such low fps will throw out almost all the information and will be useless. Hence, the animation is scaled to level it to the sensors. [slide-17-image.jpg] The remaining part is straightforward. A laser is created at each frame for every sensor, and intersection with model objects is computed using ray casting. If the calculated distance exceeds the sensor max range, it is discarded; otherwise, we label the attribute and store the location of the intersection point in our point cloud. Test Platform","title":"Overview"},{"location":"overview/#overview","text":"","title":"Overview"},{"location":"overview/#scene-generation-with-blender","text":"Not yet ready.","title":"Scene Generation with Blender"},{"location":"overview/#platforms","text":"[slide-20-image.jpg] Now that the scene is generated, it is time to add some sensors, but before that, we must specify platform objects. Platform objects are the parent objects where sensors are embedded, e.g. vehicles, drones, etc. It could be a fixed object with no trajectory(i.e. static), a dynamic object with a trajectory imported from outside or an actor(dynamic object inside the scene). Regardless, a platform with a known trajectory must be created before creating any sensors.","title":"Platforms"},{"location":"overview/#sensors","text":"[slide-22-image.jpg] With platform/platforms ready, sensors could now be created. The process is very similar to creating platforms; a location and orientation with respect to the platform must be provided. For e.g., if the sensor is placed at the platform's centre, the location must be (0, 0, 0). Remaining parameters like PRF, Scanning frequency, Channels, etc., are generic to the lidars sensors and can be copied as it is from the specification manual of the sensor.","title":"Sensors"},{"location":"overview/#cameras","text":"[slide-23-image.jpg] Adding a camera sensor is just the same as adding a lidar sensor with camera-specific parameters like focal length, iso, etc.","title":"Cameras"},{"location":"overview/#limulate","text":"[slide-25-image.jpg] This is where the magic happens. But before that note, a standard dynamic model in Blender runs at 30fps, but the laser works on 2k-800k Hz. Rendering a simulation at such low fps will throw out almost all the information and will be useless. Hence, the animation is scaled to level it to the sensors. [slide-17-image.jpg] The remaining part is straightforward. A laser is created at each frame for every sensor, and intersection with model objects is computed using ray casting. If the calculated distance exceeds the sensor max range, it is discarded; otherwise, we label the attribute and store the location of the intersection point in our point cloud.","title":"Limulate!"},{"location":"overview/#test-platform","text":"","title":"Test Platform"},{"location":"references/","text":"References Lidar Basics Blender For Blender Python API documentation visit Blender Python API API Reference Laser Module Camera Module Platform Module UI Server Processing Others","title":"References"},{"location":"references/#references","text":"","title":"References"},{"location":"references/#lidar-basics","text":"","title":"Lidar Basics"},{"location":"references/#blender","text":"For Blender Python API documentation visit Blender Python API","title":"Blender"},{"location":"references/#api-reference","text":"Laser Module Camera Module Platform Module UI Server Processing Others","title":"API Reference"},{"location":"startup/","text":"Getting Started Download Installation Windows Linux First Run","title":"Getting Started"},{"location":"startup/#getting-started","text":"","title":"Getting Started"},{"location":"startup/#download","text":"","title":"Download"},{"location":"startup/#installation","text":"","title":"Installation"},{"location":"startup/#windows","text":"","title":"Windows"},{"location":"startup/#linux","text":"","title":"Linux"},{"location":"startup/#first-run","text":"","title":"First Run"},{"location":"system_doc/","text":"Class Diagram Process Diagram","title":"System Documentation"},{"location":"system_doc/#class-diagram","text":"","title":"Class Diagram"},{"location":"system_doc/#process-diagram","text":"","title":"Process Diagram"},{"location":"tutorials/","text":"","title":"Tutorials"},{"location":"video/","text":"Video example Lorem ipsum dolor sit amet","title":"Video example"},{"location":"video/#video-example","text":"Lorem ipsum dolor sit amet","title":"Video example"},{"location":"modules/camera/","text":"Camera Module camera Camera class. It lets create and render images based on the camera paeameters Attributes: Name Type Description camera_data json camera data __init__ ( camera_data , platform_data , sensor_data ) Initialize a Camera class. Get all camera parameters Parameters: Name Type Description Default camera_data json camera data required platform_data json Platform data required sensor_data json Sensor Data required create_camera () Creates a blender camera object inside empty camera object render_frames () Renders frames for the full scene with the selected camera","title":"Camera Module"},{"location":"modules/camera/#camera-module","text":"","title":"Camera Module"},{"location":"modules/camera/#Modules.camera.camera","text":"Camera class. It lets create and render images based on the camera paeameters Attributes: Name Type Description camera_data json camera data","title":"camera"},{"location":"modules/camera/#Modules.camera.camera.__init__","text":"Initialize a Camera class. Get all camera parameters Parameters: Name Type Description Default camera_data json camera data required platform_data json Platform data required sensor_data json Sensor Data required","title":"__init__()"},{"location":"modules/camera/#Modules.camera.camera.create_camera","text":"Creates a blender camera object inside empty camera object","title":"create_camera()"},{"location":"modules/camera/#Modules.camera.camera.render_frames","text":"Renders frames for the full scene with the selected camera","title":"render_frames()"},{"location":"modules/laser/","text":"Laser Module laser_sensor Creates a laser sensor object with the provided sensor data Attributes: Name Type Description platform_data dict platform_data sensor_data dict sensor_data start_frame int First frame number to start rendering from end_frame int Last frame number to end rendering at prf int Pulse Repetition Frequency sf int Scanning Frequency rotation_type str Type of rotation csv_export_list list List containing all the intersection points data_accuracy int Set last decimal place upto which all data needs to be rounded off data_columns list List of header names of the exported csv file time_per_horizontal_dev float Time interval in seconds between each deviation deviation_per_frame float Angle of deviation between each frame (in degree) dict_data dict A dictionary containing labels and their respective id's dict_keys list List of label id dict_values list List of label names start_vfov float Start of vertical frame of view end_vfov float End of vertical field of view positive_hfov float Start of horizontal feild of view negative_hfov float End of horizontal feild of view flying_height int Mean flying height for rotating polygon type sensor frame_step int The number of frames to process before exporting hfov float Horizontal Field of view horizontal_deviation_per_pulse float Angle of deviation between each horizontal channel (in degree) laser_list list List containg names of all laserline objects laser_origin_orientation_list list List containing orientation values at each frame laser_step int The number of laser lines to process before exporting number_of_channels int Number of vertical channels number_of_hor_channels int Number of horizontal channels out_file_name str File path of the output file name preinitialized_frame bool preinitialized_frame pulses_per_frame int Number of pulses emitted at each frame rotation_type str Rotation type of the lidar sensor scanner_location list Scanner's location in the platform's local coordinate system [x,y,z] sensor_name str Sensor's name sensor_range_max int Maximum range of sensor sensor_range_min int Minimum range of sensor fixed_error_model list List containing lists of randomly generated error values for x, y and z model_range list List of all range values between sensor_range_max and sensor_range_min range_error_model array range_error_model incidence_angle_error_model array incidence_angle_error_model __init__ ( sensor_data , platform_data ) Initialises all the variables. Calls model accuracy which creates error models for range , incidence and fixed errors . laser_origin_orientation_list is created which provides sensor orientation values (omega, phi and kappa) for each frame. Parameters: Name Type Description Default sensor_data json all parameters of the sensor required platform_data json all platform parameters required all_laserlines_frame_range_iterator ( start , end ) Computes intersections for all channels across a given frame range and exports the data to csv file Parameters: Name Type Description Default start int Start frame required end int End Frame required check_intersection ( graph , origin , direction , distance ) Finds out intersections for a laser vector starting from origin in the direction , upto the given distance . Note It looks for intersection untill a point with zero transparency is found Parameters: Name Type Description Default graph bpy . context Blender scene context required origin mathutils . Vector Location of origin required direction mathutils . Vector Location of direction vector required distance int Maximum range distance required Returns a tuple of the following values Type Description Boolean hit mathutils . Vector location mathutils . Vector normal int index int object list matrix float r float g float b float a float ir create_export_file () It calls export function creates a new csv file with the set data_columns writes in w+ mode. create_sensor_frame () Creates a static frame for a laser sensor depending upon the number of channels in the vertical and horizontal FOV export ( data , mode ) Creates or appends data to a pointcloud.csv file with the given data Parameters: Name Type Description Default data list Data to be exported in list form required mode str Writing mode eg. a+ or w+ required get_fixed_error () Returns a random error value from the fixed error model Returns: Type Description list [error in x, error in y, error in z] get_horizontal_deviation_angles () Gives a list of deviation angles for the different sensor types - 1. Rotating and Osscilating - No deviation 2. Flash - Fixed angular deviation 3. Rotating Polygon - Fixed point spacing on ground Returns: Type Description np . ndarray Numpy list of angles of deviation for each laser line get_incidence_error ( angle ) Returns a error for incidence angle Args: Incidence angle at which the point exists Returns: Type Description np . ndarray List of errors for x, y, z - list(error in x, error in y, error in z) get_label_id ( obj_name ) Returns label id based on the intersected object's name. It looks for object_name in dict_values and returns its id from dict_keys. If object name is not found in the label dictionary, id is set to 999 Parameters: Name Type Description Default obj_name string Object's Name required Returns: Type Description int Label id get_range_error ( range ) Returns a list of random values based on input range Generates random error from a normal distribution with a standard deviation for the given range from range_error_model Parameters: Name Type Description Default range float Range at which the point exists required Returns: Type Description np . ndarray Error in range laser_object_group_frame_range_iterator ( start , end , laserline_id ) Computes intersections for a number of channels = laser_step across a given frame range and exports the data to pointcloud.csv file Parameters: Name Type Description Default start int Start frame required end int End Frame required laserline_id int Id of the selected laserline required laserline_currentframe_interaction ( frame , selected_laserline_id ) Computes intersections for a selected laserline on the given frame Returns: [x,y,z,t,label,instance_id,incidence_angle,self.sensor_name,frame,channel_id,r,g,b,a,intensity] lidar_sensor_main () Main class to handle creation of sensor frame and to check intersections model_accuracy () Generates a accuracy model based on the error type orientation_csv_static_not_rotating () Creates a positition orientation list for a stationary non rotating type of scanner orientation_csv_static_o () Generates a list for orientation values for a Osscilating type sensor orientation_csv_static_r () Generates a list for orientation values for a rotating type sensor rotating_polygon_iterator () Iterates through all laserlines and frames - with initializing a set of laserlines and checking interesections for sets of frames Since there are large number of laserlines for a rotating polygon type sensor following modifications are made: All laserlines are processed in batches of the defined laser_step The laserline objects are initialized on demand unlike other senor setups where preinitialized_frame is set to True visulize_sensor_frame () Visulises the sensor frame","title":"Laser Module"},{"location":"modules/laser/#laser-module","text":"","title":"Laser Module"},{"location":"modules/laser/#Modules.laser.laser_sensor","text":"Creates a laser sensor object with the provided sensor data Attributes: Name Type Description platform_data dict platform_data sensor_data dict sensor_data start_frame int First frame number to start rendering from end_frame int Last frame number to end rendering at prf int Pulse Repetition Frequency sf int Scanning Frequency rotation_type str Type of rotation csv_export_list list List containing all the intersection points data_accuracy int Set last decimal place upto which all data needs to be rounded off data_columns list List of header names of the exported csv file time_per_horizontal_dev float Time interval in seconds between each deviation deviation_per_frame float Angle of deviation between each frame (in degree) dict_data dict A dictionary containing labels and their respective id's dict_keys list List of label id dict_values list List of label names start_vfov float Start of vertical frame of view end_vfov float End of vertical field of view positive_hfov float Start of horizontal feild of view negative_hfov float End of horizontal feild of view flying_height int Mean flying height for rotating polygon type sensor frame_step int The number of frames to process before exporting hfov float Horizontal Field of view horizontal_deviation_per_pulse float Angle of deviation between each horizontal channel (in degree) laser_list list List containg names of all laserline objects laser_origin_orientation_list list List containing orientation values at each frame laser_step int The number of laser lines to process before exporting number_of_channels int Number of vertical channels number_of_hor_channels int Number of horizontal channels out_file_name str File path of the output file name preinitialized_frame bool preinitialized_frame pulses_per_frame int Number of pulses emitted at each frame rotation_type str Rotation type of the lidar sensor scanner_location list Scanner's location in the platform's local coordinate system [x,y,z] sensor_name str Sensor's name sensor_range_max int Maximum range of sensor sensor_range_min int Minimum range of sensor fixed_error_model list List containing lists of randomly generated error values for x, y and z model_range list List of all range values between sensor_range_max and sensor_range_min range_error_model array range_error_model incidence_angle_error_model array incidence_angle_error_model","title":"laser_sensor"},{"location":"modules/laser/#Modules.laser.laser_sensor.__init__","text":"Initialises all the variables. Calls model accuracy which creates error models for range , incidence and fixed errors . laser_origin_orientation_list is created which provides sensor orientation values (omega, phi and kappa) for each frame. Parameters: Name Type Description Default sensor_data json all parameters of the sensor required platform_data json all platform parameters required","title":"__init__()"},{"location":"modules/laser/#Modules.laser.laser_sensor.all_laserlines_frame_range_iterator","text":"Computes intersections for all channels across a given frame range and exports the data to csv file Parameters: Name Type Description Default start int Start frame required end int End Frame required","title":"all_laserlines_frame_range_iterator()"},{"location":"modules/laser/#Modules.laser.laser_sensor.check_intersection","text":"Finds out intersections for a laser vector starting from origin in the direction , upto the given distance . Note It looks for intersection untill a point with zero transparency is found Parameters: Name Type Description Default graph bpy . context Blender scene context required origin mathutils . Vector Location of origin required direction mathutils . Vector Location of direction vector required distance int Maximum range distance required Returns a tuple of the following values Type Description Boolean hit mathutils . Vector location mathutils . Vector normal int index int object list matrix float r float g float b float a float ir","title":"check_intersection()"},{"location":"modules/laser/#Modules.laser.laser_sensor.create_export_file","text":"It calls export function creates a new csv file with the set data_columns writes in w+ mode.","title":"create_export_file()"},{"location":"modules/laser/#Modules.laser.laser_sensor.create_sensor_frame","text":"Creates a static frame for a laser sensor depending upon the number of channels in the vertical and horizontal FOV","title":"create_sensor_frame()"},{"location":"modules/laser/#Modules.laser.laser_sensor.export","text":"Creates or appends data to a pointcloud.csv file with the given data Parameters: Name Type Description Default data list Data to be exported in list form required mode str Writing mode eg. a+ or w+ required","title":"export()"},{"location":"modules/laser/#Modules.laser.laser_sensor.get_fixed_error","text":"Returns a random error value from the fixed error model Returns: Type Description list [error in x, error in y, error in z]","title":"get_fixed_error()"},{"location":"modules/laser/#Modules.laser.laser_sensor.get_horizontal_deviation_angles","text":"Gives a list of deviation angles for the different sensor types - 1. Rotating and Osscilating - No deviation 2. Flash - Fixed angular deviation 3. Rotating Polygon - Fixed point spacing on ground Returns: Type Description np . ndarray Numpy list of angles of deviation for each laser line","title":"get_horizontal_deviation_angles()"},{"location":"modules/laser/#Modules.laser.laser_sensor.get_incidence_error","text":"Returns a error for incidence angle Args: Incidence angle at which the point exists Returns: Type Description np . ndarray List of errors for x, y, z - list(error in x, error in y, error in z)","title":"get_incidence_error()"},{"location":"modules/laser/#Modules.laser.laser_sensor.get_label_id","text":"Returns label id based on the intersected object's name. It looks for object_name in dict_values and returns its id from dict_keys. If object name is not found in the label dictionary, id is set to 999 Parameters: Name Type Description Default obj_name string Object's Name required Returns: Type Description int Label id","title":"get_label_id()"},{"location":"modules/laser/#Modules.laser.laser_sensor.get_range_error","text":"Returns a list of random values based on input range Generates random error from a normal distribution with a standard deviation for the given range from range_error_model Parameters: Name Type Description Default range float Range at which the point exists required Returns: Type Description np . ndarray Error in range","title":"get_range_error()"},{"location":"modules/laser/#Modules.laser.laser_sensor.laser_object_group_frame_range_iterator","text":"Computes intersections for a number of channels = laser_step across a given frame range and exports the data to pointcloud.csv file Parameters: Name Type Description Default start int Start frame required end int End Frame required laserline_id int Id of the selected laserline required","title":"laser_object_group_frame_range_iterator()"},{"location":"modules/laser/#Modules.laser.laser_sensor.laserline_currentframe_interaction","text":"Computes intersections for a selected laserline on the given frame Returns: [x,y,z,t,label,instance_id,incidence_angle,self.sensor_name,frame,channel_id,r,g,b,a,intensity]","title":"laserline_currentframe_interaction()"},{"location":"modules/laser/#Modules.laser.laser_sensor.lidar_sensor_main","text":"Main class to handle creation of sensor frame and to check intersections","title":"lidar_sensor_main()"},{"location":"modules/laser/#Modules.laser.laser_sensor.model_accuracy","text":"Generates a accuracy model based on the error type","title":"model_accuracy()"},{"location":"modules/laser/#Modules.laser.laser_sensor.orientation_csv_static_not_rotating","text":"Creates a positition orientation list for a stationary non rotating type of scanner","title":"orientation_csv_static_not_rotating()"},{"location":"modules/laser/#Modules.laser.laser_sensor.orientation_csv_static_o","text":"Generates a list for orientation values for a Osscilating type sensor","title":"orientation_csv_static_o()"},{"location":"modules/laser/#Modules.laser.laser_sensor.orientation_csv_static_r","text":"Generates a list for orientation values for a rotating type sensor","title":"orientation_csv_static_r()"},{"location":"modules/laser/#Modules.laser.laser_sensor.rotating_polygon_iterator","text":"Iterates through all laserlines and frames - with initializing a set of laserlines and checking interesections for sets of frames Since there are large number of laserlines for a rotating polygon type sensor following modifications are made: All laserlines are processed in batches of the defined laser_step The laserline objects are initialized on demand unlike other senor setups where preinitialized_frame is set to True","title":"rotating_polygon_iterator()"},{"location":"modules/laser/#Modules.laser.laser_sensor.visulize_sensor_frame","text":"Visulises the sensor frame","title":"visulize_sensor_frame()"},{"location":"modules/others/","text":"Others","title":"Others"},{"location":"modules/others/#others","text":"","title":"Others"},{"location":"modules/platform/","text":"Platform Module platform_class Platform class. It lets us add sensors and cameras __init__ ( platform_data , sensor_data ) Initialize and create a platform object in Blender Scene. If a trajectory file is avaialable animates the platform based on the position and orientation at each frame Else it links the platform to a mentioned blender object add_camera ( camera_data ) Creates a camera child object inside platform object add_sensor ( sensor_data ) Creates a sensor child object inside platform object","title":"Platform Module"},{"location":"modules/platform/#platform-module","text":"","title":"Platform Module"},{"location":"modules/platform/#Modules.limulator_platform.platform_class","text":"Platform class. It lets us add sensors and cameras","title":"platform_class"},{"location":"modules/platform/#Modules.limulator_platform.platform_class.__init__","text":"Initialize and create a platform object in Blender Scene. If a trajectory file is avaialable animates the platform based on the position and orientation at each frame Else it links the platform to a mentioned blender object","title":"__init__()"},{"location":"modules/platform/#Modules.limulator_platform.platform_class.add_camera","text":"Creates a camera child object inside platform object","title":"add_camera()"},{"location":"modules/platform/#Modules.limulator_platform.platform_class.add_sensor","text":"Creates a sensor child object inside platform object","title":"add_sensor()"},{"location":"modules/server_processing/","text":"Server Processing","title":"Server Processing"},{"location":"modules/server_processing/#server-processing","text":"","title":"Server Processing"},{"location":"modules/ui/","text":"UI Module LIST_OT_DeleteItem Bases: Operator Delete the selected item from the list. LIST_OT_DeleteLabelItem Bases: Operator Delete the selected item from the list. LIST_OT_EmptyLabelList Bases: Operator Reevaluates the Label list. LIST_OT_ExportLabelList Bases: Operator Exports the Label list. LIST_OT_MoveItem Bases: Operator Move an item in the list. move_index () Move index of an item render queue while clamping it. LIST_OT_NewItem Bases: Operator Add a new item to the list. LIST_OT_NewLabelItem Bases: Operator Add a new label to list. LabelListItem Bases: PropertyGroup Group of properties representing an label item in the list. ListItem Bases: PropertyGroup Group of properties representing an item in the list. MY_UL_List Bases: UIList Demo UIList. SCENE_LABEL_List Bases: UIList Display Labels createNew ( sensor_count , camera_count ) Creates a empty json structure for a new platform design Args: sensor_count (int) - Count of the lidar sensors to be added camera_count (int) - Count of the camera sensors to be added delete_platforms () Deletes all pre generated sensor objects Returns: None export_json ( override = False ) Exports json file containing all platform, lidar and camera parameters to a given location or overrides a given json file with new data import_label_dict () Imports label dictionary json file from the provided path for label_dict_filepath read_JSON_data () Reads json file containing all platform, lidar and camera parameters to a given location","title":"UI"},{"location":"modules/ui/#ui-module","text":"","title":"UI Module"},{"location":"modules/ui/#main2.LIST_OT_DeleteItem","text":"Bases: Operator Delete the selected item from the list.","title":"LIST_OT_DeleteItem"},{"location":"modules/ui/#main2.LIST_OT_DeleteLabelItem","text":"Bases: Operator Delete the selected item from the list.","title":"LIST_OT_DeleteLabelItem"},{"location":"modules/ui/#main2.LIST_OT_EmptyLabelList","text":"Bases: Operator Reevaluates the Label list.","title":"LIST_OT_EmptyLabelList"},{"location":"modules/ui/#main2.LIST_OT_ExportLabelList","text":"Bases: Operator Exports the Label list.","title":"LIST_OT_ExportLabelList"},{"location":"modules/ui/#main2.LIST_OT_MoveItem","text":"Bases: Operator Move an item in the list.","title":"LIST_OT_MoveItem"},{"location":"modules/ui/#main2.LIST_OT_MoveItem.move_index","text":"Move index of an item render queue while clamping it.","title":"move_index()"},{"location":"modules/ui/#main2.LIST_OT_NewItem","text":"Bases: Operator Add a new item to the list.","title":"LIST_OT_NewItem"},{"location":"modules/ui/#main2.LIST_OT_NewLabelItem","text":"Bases: Operator Add a new label to list.","title":"LIST_OT_NewLabelItem"},{"location":"modules/ui/#main2.LabelListItem","text":"Bases: PropertyGroup Group of properties representing an label item in the list.","title":"LabelListItem"},{"location":"modules/ui/#main2.ListItem","text":"Bases: PropertyGroup Group of properties representing an item in the list.","title":"ListItem"},{"location":"modules/ui/#main2.MY_UL_List","text":"Bases: UIList Demo UIList.","title":"MY_UL_List"},{"location":"modules/ui/#main2.SCENE_LABEL_List","text":"Bases: UIList Display Labels","title":"SCENE_LABEL_List"},{"location":"modules/ui/#main2.createNew","text":"Creates a empty json structure for a new platform design Args: sensor_count (int) - Count of the lidar sensors to be added camera_count (int) - Count of the camera sensors to be added","title":"createNew()"},{"location":"modules/ui/#main2.delete_platforms","text":"Deletes all pre generated sensor objects Returns: None","title":"delete_platforms()"},{"location":"modules/ui/#main2.export_json","text":"Exports json file containing all platform, lidar and camera parameters to a given location or overrides a given json file with new data","title":"export_json()"},{"location":"modules/ui/#main2.import_label_dict","text":"Imports label dictionary json file from the provided path for label_dict_filepath","title":"import_label_dict()"},{"location":"modules/ui/#main2.read_JSON_data","text":"Reads json file containing all platform, lidar and camera parameters to a given location","title":"read_JSON_data()"}]}